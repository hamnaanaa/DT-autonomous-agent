{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision import transforms\n",
    "\n",
    "from dataloader.dataloader import DTSegmentationDataset\n",
    "from model.model import DTSegmentationNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 194, val size: 49\n"
     ]
    }
   ],
   "source": [
    "dataset = DTSegmentationDataset()\n",
    "\n",
    "# Split the dataset into train and test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train, val = random_split(dataset, [train_size, test_size])\n",
    "print(f\"Train size: {len(train)}, val size: {len(val)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_hparams = {\n",
    "    # --- Model ---\n",
    "    # | Model hyperparameters\n",
    "    'num_classes': 5,\n",
    "    # | Optimization hyperparameters\n",
    "    \"learning_rate\": 0.0625,\n",
    "    \"weight_decay\": 0.000000625,\n",
    "    \"lr_decay\": 0.25,\n",
    "    \n",
    "    # --- Dataloader (Hardware-specific) ---\n",
    "    \"batch_size\": 12,\n",
    "    \"num_workers\": 2,\n",
    "}\n",
    "\n",
    "model = DTSegmentationNetwork(overfit_hparams)\n",
    "\n",
    "# Overfit for testing\n",
    "early_stop_overfit_callback = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=150,\n",
    "    min_delta=0.0005,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    log_every_n_steps=1,\n",
    "    max_epochs=150,\n",
    "    overfit_batches=1,\n",
    "    callbacks=[early_stop_overfit_callback]\n",
    ")\n",
    "\n",
    "# image, target = train[0]\n",
    "# # print(f'image: {image.shape}, target: {target.shape}')\n",
    "# result = torch.argmax(target, dim=0)\n",
    "# print(f'image: {image.shape}, result: {result.shape}, value range: {torch.min(result)}-{torch.max(result)}')\n",
    "\n",
    "trainer.fit(model, DataLoader(train, shuffle=False, batch_size=1), DataLoader(val, shuffle=False, batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape: torch.Size([480, 640]), value range: 0-3\n",
      "Result shape: torch.Size([1, 480, 640]), value range: 0-3\n"
     ]
    }
   ],
   "source": [
    "# visualize the overfitted results\n",
    "img, target = train[0]\n",
    "print(f\"Target shape: {target.shape}, value range: {torch.min(target)}-{torch.max(target)}\")\n",
    "result = torch.argmax(model(img.unsqueeze(0)), dim=1)\n",
    "print(f\"Result shape: {result.shape}, value range: {torch.min(result)}-{torch.max(result)}\")\n",
    "pil_transform = transforms.ToPILImage()\n",
    "pil_transform(img).show(title=\"image\")\n",
    "pil_transform(DTSegmentationDataset.label_img_to_rgb(target)).show(title=\"ground truth\")\n",
    "pil_transform(DTSegmentationDataset.label_img_to_rgb(result[0])).show(title=\"prediction\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | LRASPP | 3.2 M \n",
      "---------------------------------\n",
      "246 K     Trainable params\n",
      "3.0 M     Non-trainable params\n",
      "3.2 M     Total params\n",
      "12.875    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 17/17 [00:57<00:00,  3.40s/it, loss=0.708, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 17/17 [01:18<00:00,  4.61s/it, loss=0.498, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.175 >= min_delta = 0.01. New best score: 0.912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 17/17 [01:15<00:00,  4.44s/it, loss=0.394, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.227 >= min_delta = 0.01. New best score: 0.686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 17/17 [01:15<00:00,  4.42s/it, loss=0.354, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.160 >= min_delta = 0.01. New best score: 0.525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 17/17 [01:16<00:00,  4.49s/it, loss=0.331, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.093 >= min_delta = 0.01. New best score: 0.432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 17/17 [01:15<00:00,  4.45s/it, loss=0.319, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.051 >= min_delta = 0.01. New best score: 0.381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 17/17 [01:15<00:00,  4.45s/it, loss=0.282, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.046 >= min_delta = 0.01. New best score: 0.335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 17/17 [01:16<00:00,  4.47s/it, loss=0.307, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.031 >= min_delta = 0.01. New best score: 0.304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 17/17 [01:15<00:00,  4.43s/it, loss=0.262, v_num=0]Epoch 00017: reducing learning rate of group 0 to 1.5625e-02.\n",
      "Epoch 17: 100%|██████████| 17/17 [01:17<00:00,  4.58s/it, loss=0.246, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.01. New best score: 0.288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 17/17 [01:17<00:00,  4.56s/it, loss=0.201, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.022 >= min_delta = 0.01. New best score: 0.267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 17/17 [01:16<00:00,  4.49s/it, loss=0.211, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.01. New best score: 0.255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 17/17 [01:15<00:00,  4.43s/it, loss=0.197, v_num=0]Epoch 00033: reducing learning rate of group 0 to 3.9062e-03.\n",
      "Epoch 35: 100%|██████████| 17/17 [01:15<00:00,  4.47s/it, loss=0.218, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 7 records. Best score: 0.255. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 17/17 [01:15<00:00,  4.47s/it, loss=0.218, v_num=0]\n",
      "Saving model... model.pt\n"
     ]
    }
   ],
   "source": [
    "hparams = {\n",
    "    # --- Model ---\n",
    "    # | Model hyperparameters\n",
    "    'num_classes': 5,\n",
    "    # | Optimization hyperparameters\n",
    "    \"learning_rate\": 0.0625,\n",
    "    \"weight_decay\": 0.000000625,\n",
    "    \"lr_decay\": 0.25,\n",
    "    \n",
    "    # --- Dataloader (Hardware-specific) ---\n",
    "    \"batch_size\": 16,\n",
    "    \"num_workers\": 4,\n",
    "}\n",
    "\n",
    "model = DTSegmentationNetwork(hparams)\n",
    "\n",
    "# Training procedure\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=7,\n",
    "    min_delta=0.01,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    log_every_n_steps=1,\n",
    "    # For new MacBooks\n",
    "    # accelerator=\"mps\",\n",
    "    # devices=1,\n",
    "    callbacks=[early_stop_callback]\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=hparams['batch_size'], num_workers=hparams['num_workers'], shuffle=True)\n",
    "val_dataloader = DataLoader(val, batch_size=hparams['batch_size'], num_workers=hparams['num_workers'])\n",
    "\n",
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n",
    "model.save(\"model.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model_v3_0_302.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape: torch.Size([640, 480]), value range: 0-4\n",
      "Result shape: torch.Size([1, 640, 480]), value range: 0-4\n"
     ]
    }
   ],
   "source": [
    "# visualize the model results\n",
    "img, target = val[13]\n",
    "print(f\"Target shape: {target.shape}, value range: {torch.min(target)}-{torch.max(target)}\")\n",
    "result = torch.argmax(model(img.unsqueeze(0)), dim=1)\n",
    "print(f\"Result shape: {result.shape}, value range: {torch.min(result)}-{torch.max(result)}\")\n",
    "pil_transform = transforms.ToPILImage()\n",
    "pil_transform(img).show(title=\"image\")\n",
    "pil_transform(DTSegmentationDataset.label_img_to_rgb(target)).show(title=\"ground truth\")\n",
    "rgb_prediction = DTSegmentationDataset.label_img_to_rgb(result[0])\n",
    "pil_prediction = pil_transform(rgb_prediction)\n",
    "pil_prediction.show(title=\"prediction\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average coordinate of the road\n",
    "road_mask = np.argwhere(rgb_prediction == DTSegmentationDataset.SEGM_LABELS['Ego Lane']['rgb_value'])\n",
    "road_center_y, road_center_x = np.ceil(np.mean(road_mask, axis=0)[:2])\n",
    "\n",
    "drawer = ImageDraw.Draw(pil_prediction)\n",
    "# Draw two circles (bigger and smaller) centered on road center coordinate\n",
    "RADIUS = 20\n",
    "drawer.ellipse((road_center_x - RADIUS, road_center_y - RADIUS, road_center_x + RADIUS, road_center_y + RADIUS), fill='green')\n",
    "drawer.ellipse((road_center_x - 5, road_center_y - 5, road_center_x + 5, road_center_y + 5), fill='orange')\n",
    "# Draw a vertical line on the center of the image\n",
    "drawer.line((pil_prediction.width / 2, 0, pil_prediction.width / 2, pil_prediction.height), fill='red')\n",
    "# Draw a horizontal line from the center of the image to the road center\n",
    "drawer.line((pil_prediction.width / 2, road_center_y, road_center_x, road_center_y), fill='blue')\n",
    "# Draw two lines going from the corners of the image to the road center\n",
    "drawer.line((0, 0, road_center_x, road_center_y), fill='yellow', width=2)\n",
    "drawer.line((pil_prediction.width, 0, road_center_x, road_center_y), fill='yellow', width=2)\n",
    "\n",
    "pil_prediction.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: <built-in method size of Tensor object at 0x7f943245b330>\n",
      "Result shape: torch.Size([1, 878, 1180]), value range: 0-2\n"
     ]
    }
   ],
   "source": [
    "# Load and visualize the test image\n",
    "img = transforms.ToTensor()(Image.open(\"offline learning/semantic segmentation/data/frames_test/track_test_6.png\"))\n",
    "print(f\"Image shape: {img.size}\")\n",
    "result = torch.argmax(model(img.unsqueeze(0)), dim=1)\n",
    "print(f\"Result shape: {result.shape}, value range: {torch.min(result)}-{torch.max(result)}\")\n",
    "pil_transform = transforms.ToPILImage()\n",
    "pil_transform(img).show(title=\"image\")\n",
    "rgb_prediction = DTSegmentationDataset.label_img_to_rgb(result[0])\n",
    "pil_prediction = pil_transform(rgb_prediction)\n",
    "pil_prediction.show(title=\"prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3315f46222374d13566524152beecd401bb6de98e11336215c532ce4113572da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
