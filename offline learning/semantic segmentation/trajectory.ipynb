{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torchvision import transforms\n",
    "\n",
    "from model.model import DTSegmentationNetwork\n",
    "from dataloader.dataloader import DTSegmentationDataset\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = torch.load('model_v8_0_029.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 images\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_IMAGES = \"testing/out/\"\n",
    "# Fetch all image names from the folder\n",
    "image_names = [f for f in os.listdir(PATH_TO_IMAGES) if os.path.isfile(os.path.join(PATH_TO_IMAGES, f)) and f.startswith('image_')]\n",
    "print(f\"Found {len(image_names)} images\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image image_1673208199.9477482.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image image_1673208177.049033.png...\n",
      "Loading image image_1673208078.994764.png...\n",
      "Loading image image_1673208217.92832.png...\n",
      "Loading image image_1673208224.555704.png...\n",
      "Loading image image_1673208134.1926.png...\n",
      "Loading image image_1673208122.1896372.png...\n",
      "Loading image image_1673208206.550975.png...\n",
      "Loading image image_1673208168.844874.png...\n",
      "Loading image image_1673208193.854777.png...\n",
      "Loading image image_1673208243.706476.png...\n",
      "Loading image image_1673208152.717825.png...\n",
      "Loading image image_1673208161.065065.png...\n",
      "Loading image image_1673208187.4467032.png...\n",
      "Loading image image_1673208237.516394.png...\n",
      "Loading image image_1673208250.310034.png...\n",
      "Loading image image_1673208181.921555.png...\n",
      "Loading image image_1673208143.3403552.png...\n",
      "Loading image image_1673208231.460027.png...\n",
      "Average time needed to feed an image through the network: 0.165 seconds\n"
     ]
    }
   ],
   "source": [
    "# For all images loaded, measure the average time needed to feed the image through the network\n",
    "# device = torch.device('cpu')\n",
    "# print(f\"Using device {device}\")\n",
    "# model = model.to(device)\n",
    "model.eval()\n",
    "avg_time = 0\n",
    "tensor_transform = transforms.ToTensor()\n",
    "for image_name in image_names:\n",
    "    # Load the image\n",
    "    print(f\"Loading image {image_name}...\")\n",
    "    start_time = time.time()\n",
    "    img = Image.open(os.path.join(PATH_TO_IMAGES, image_name)).convert('RGB')\n",
    "    # Convert the image to a tensor\n",
    "    img = tensor_transform(img)\n",
    "    convert_time = time.time() - start_time\n",
    "    # Move the image to the device\n",
    "    # img = img.to(device)\n",
    "    # Feed the image through the network\n",
    "    prediction = torch.argmax(model(img.unsqueeze(0)), dim=1)[0]\n",
    "    prediction_time = time.time() - (start_time + convert_time)    \n",
    "    avg_time += prediction_time\n",
    "\n",
    "    # pil_prediction = transforms.ToPILImage()(DTSegmentationDataset.label_img_to_rgb(prediction))\n",
    "    # pil_prediction.save(f\"testing/out/{image_name.replace('image_', 'prediction_middlelane_')}\")\n",
    "    \n",
    "avg_time /= len(image_names)\n",
    "print(f\"Average time needed to feed an image through the network: {avg_time:.3f} seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mass center of green pixels in the prediction\n",
    "# (the mass center of the ego lane)\n",
    "# mass_center = np.array(np.where(np.array(prediction) == DTSegmentationDataset.SEGM_LABELS['Ego Lane']['rgb_value'])).mean(axis=1).astype(int)\n",
    "\n",
    "# # Draw a circle where the mass center is (used when detecting road and not lane (!))\n",
    "# drawer = ImageDraw.Draw(merged)\n",
    "# drawer.ellipse((mass_center[1] - 5, mass_center[0] - 5, mass_center[1] + 5, mass_center[0] + 5), fill=(255, 0, 0))\n",
    "# # Draw a circle in the image middle + a vertical line in the middle\n",
    "# drawer.ellipse((image.width // 2 - 5, image.height // 2 - 5, image.width // 2 + 5, image.height // 2 + 5), fill=(0, 0, 0))\n",
    "# drawer.line((image.width // 2, 0, image.width // 2, image.height), fill=(0, 0, 0), width=3)\n",
    "# # Draw a line from the center of the image to the mass center + a horizontal line from the mass center to the middle line\n",
    "# drawer.line((image.width // 2, image.height // 2, mass_center[1], mass_center[0]), fill=(0, 0, 0), width=3)\n",
    "# drawer.line((mass_center[1], mass_center[0], image.width // 2, mass_center[0]), fill=(0, 0, 0), width=3)\n",
    "# # Add a caption to the line from the mass center to the middle line with its length\n",
    "# drawer.text((mass_center[1] + 10, mass_center[0] - 10), f\"{abs(mass_center[1] - image.width // 2)} px\", fill=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing image image_1673208199.9477482.png and its prediction\n",
      "Pasting image image_1673208199.9477482.png at (0, 0)\n",
      "Pasting image image_1673208177.049033.png at (640, 0)\n",
      "Pasting image image_1673208078.994764.png at (1280, 0)\n",
      "Pasting image image_1673208217.92832.png at (1920, 0)\n",
      "Pasting image image_1673208224.555704.png at (0, 384)\n",
      "Pasting image image_1673208134.1926.png at (640, 384)\n",
      "Pasting image image_1673208122.1896372.png at (1280, 384)\n",
      "Pasting image image_1673208206.550975.png at (1920, 384)\n",
      "Pasting image image_1673208168.844874.png at (0, 768)\n",
      "Pasting image image_1673208193.854777.png at (640, 768)\n",
      "Pasting image image_1673208243.706476.png at (1280, 768)\n",
      "Pasting image image_1673208152.717825.png at (1920, 768)\n",
      "Pasting image image_1673208161.065065.png at (0, 1152)\n",
      "Pasting image image_1673208187.4467032.png at (640, 1152)\n",
      "Pasting image image_1673208237.516394.png at (1280, 1152)\n",
      "Pasting image image_1673208250.310034.png at (1920, 1152)\n",
      "Pasting image image_1673208181.921555.png at (0, 1536)\n",
      "Pasting image image_1673208143.3403552.png at (640, 1536)\n",
      "Pasting image image_1673208231.460027.png at (1280, 1536)\n"
     ]
    }
   ],
   "source": [
    "CUT_TOP_FACTOR = 0.2\n",
    "\n",
    "# Generate a single image that has all images with their predictions overlayed in a grid (4 pictures per row)\n",
    "final_image = Image.new('RGB', (640 * 4, int(480 * (1 - CUT_TOP_FACTOR)) * (len(image_names) // 4 + 1)))\n",
    "\n",
    "for index, image_name in enumerate(image_names):\n",
    "    # Load the image and the prediction\n",
    "    image = Image.open(PATH_TO_IMAGES + image_name).convert(\"RGB\")\n",
    "    prediction = Image.open(PATH_TO_IMAGES + image_name.replace('image_', 'prediction_middlelane_')).convert(\"RGB\")\n",
    "    # Cut the top CUT_TOP_FACTOR % of the image and the prediction\n",
    "    image = image.crop((0, int(image.height * CUT_TOP_FACTOR), image.width, image.height))\n",
    "    prediction = prediction.crop((0, int(prediction.height * CUT_TOP_FACTOR), prediction.width, prediction.height))\n",
    "\n",
    "    # Overlay the prediction on the image\n",
    "    merged = Image.blend(image, prediction, 0.5)\n",
    "    \n",
    "    # Draw a line fitted all green pixels in the prediction if there are any\n",
    "    if np.any(np.array(prediction) == DTSegmentationDataset.SEGM_LABELS['Ego Lane']['rgb_value']):\n",
    "        drawer = ImageDraw.Draw(merged)\n",
    "        # Get all green pixels in the prediction\n",
    "        lane_pixels = np.where(np.array(prediction) == DTSegmentationDataset.SEGM_LABELS['Ego Lane']['rgb_value'])\n",
    "        \n",
    "        # Use a fitting function that is robust for outliers\n",
    "        # (https://stackoverflow.com/questions/22239691/code-for-line-of-best-fit-of-a-scatter-plot-in-python)\n",
    "        line = np.polyfit(lane_pixels[1], lane_pixels[0], 1, full=True)\n",
    "        # Draw the line\n",
    "        drawer.line((0, line[0][1], image.width, line[0][0] * image.width + line[0][1]), fill=(255, 0, 0), width=5)\n",
    "        # # Add a caption with bigger font size to the line with its angle\n",
    "        angle = np.arctan(line[0][0]) * 180 / np.pi + 90\n",
    "        drawer.text((10, 10), f\"Angle: {angle:.2f}Â°\", fill=(255, 0, 0))\n",
    "    \n",
    "    if index == 0:\n",
    "        print(f\"Showing image {image_name} and its prediction\")\n",
    "        image.show()\n",
    "        prediction.show()\n",
    "    # Paste the image with the prediction and the lines on the final image\n",
    "    width_offset, height_offset = index % 4 * 640, (index // 4) * int(480 * (1 - CUT_TOP_FACTOR))\n",
    "    print(f\"Pasting image {image_name} at ({width_offset}, {height_offset})\")\n",
    "    final_image.paste(merged, (width_offset, height_offset))\n",
    "\n",
    "final_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:09:04) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3315f46222374d13566524152beecd401bb6de98e11336215c532ce4113572da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
